{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA-eval : evaluating Principal Component Analysis (PCA) performance in high-dimensional data\n",
    "\n",
    "I created this simple package to evaluate whether PCA sucessfully carries most of the data variance in single-cell genomics. It should work for any high-dimensional data. In a nutshell, this helps practitioners evaluate whether they can perform PCA for denoising and reduction of computational burden before proceeding with sophisticated non-linear methods.\n",
    "\n",
    "Let's start to see how to use this package with some simple simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcaeval.pca_eval import (generate_linear_data,\n",
    "                              generate_uncorrelated_data,\n",
    "                              evaluate_matrix,\n",
    "                              plot_sing_vals_exp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll simulate linearly correlated data and uncorrelated data to validate the analysis pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_test = generate_linear_data(n=10000, d=2000, n_classes=10, redundancy=0.1, noise=0.1, seed=0)\n",
    "uncorrelated_test = generate_uncorrelated_data(n=10000, d=2000, seed=0)\n",
    "\n",
    "datasets = {'Linear data':linear_test, 'Uncorrelated data':uncorrelated_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll evaluate these data matrices with our `evaluate_matrix()` function. It yields a dictionary of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "for i_data, name in enumerate(datasets):\n",
    "    r_dict = evaluate_matrix(\n",
    "        datasets[name], n_pcs=100, dimred_estimator=False,\n",
    "     clustering_estimator=False, n_jobs=-1, verbose=True\n",
    "     )\n",
    "    results_dict[name] = r_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's plot the covariance eigenspectrum (singular values and cumulative explained variance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sing_vals_exp_var(results_dict, fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see, PCs explain very little variance and fail to meaningfully represent the data when it is not linearly correlated.\n",
    "\n",
    "An example of how this can be important is neighborhood graph construction: often machine-learning or bioinformatics practitioners learn nearest-neighbors graphs on top PCs instead of using the full data. However, the graph learned from the PCs is poorly correlated with the graph learned from the full data when features are not linearly correlated (i.e. data cannot be represented by hyperplanes of maximum covariance):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Spearman R correlation between the k-nearest-neighbors graphs learned from the data and the Principal Components:' +\n",
    "'\\n Linear data: %f'%results_dict['Linear data']['graph_correlation'] + '\\n Uncorrelated data: %f'%results_dict['Uncorrelated data']['graph_correlation'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, as we can see, building the k-nearest-neighbors graph from PCs when data features are not linearly correlated is often a bad idea. The same goes for other algorithms with locality-preserving characteristics, such as non-linear dimensional reduction.\n",
    "\n",
    "Let's see how this goes for UMAP, a very popular dimensional reduction technique. Any method can be evaluated within `pca-eval`, but we currently expect dimensional reduction methods  to have a `.fit_transform(X)` method. If no method is provided, `pca-eval` will use t-SNE by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install umap if you don't have it (c'mon, you should already have it, its fabulous)\n",
    "#%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap_estimator = UMAP(n_neighbors=10, min_dist=0.3, n_components=2, random_state=42)\n",
    "\n",
    "results_dict = {}\n",
    "for i_data, name in enumerate(datasets):\n",
    "    r_dict = evaluate_matrix(\n",
    "        datasets[name], n_pcs=100, dimred_estimator=umap_estimator,\n",
    "     clustering_estimator=kmeans_estimator, n_jobs=-1, verbose=True\n",
    "     )\n",
    "    results_dict[name] = r_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcaeval.pca_eval import print_dict_results\n",
    "\n",
    "print_dict_results(results_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how this goes in single-cell genomics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "from pcaeval.pca_eval import evaluate_anndata, plot_sing_vals_exp_var\n",
    "adata = sc.datasets.pbmc3k()\n",
    "\n",
    "# Input: a filtered, unnormalized AnnData object\n",
    "# If already normalized, set norm_log_hvg=False\n",
    "res_dict, adata = evaluate_anndata(adata, norm_log_hvg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict = {'PBMC3K':res_dict}\n",
    "print_dict_results(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sing_vals_exp_var(res_dict, dataset=False, fontsize=10)\n",
    "# datset=False means that the dictionary is not a dictionary of dictionaries with multiple datasets, but\n",
    "# a dictionary with results from a single dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As easily observed, single-cell genomics data should be considered as not having linearly correlated variables. Thus, PCA is unsuited for its preprocessing or analysis unless proven otherwise. \n",
    "\n",
    "----------\n",
    "NOTICE: \n",
    "As a matter of fact, nearly all published literature in single-cell genomics uses PCA for processing, so one cannot rigorously trust any of it. As despairing as this might seem, I see this as an opportunity for the community to do better rather than just following tutorials from toolkits such as Seurat and Scanpy (which do PCA preprocessing by default). It is also an opportunity to work together as a community, since all of this data will need to be reanalysed so that artifacts and distortions can be identified.\n",
    "\n",
    "One may wonder how the communitty allowed it to come to this. I believe the answer lies somewhere between the unwillingness to address mistakes in disregard of how malicious they might be for science and the inability to question whether what is done by all is actually correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
